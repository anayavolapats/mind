<html>
<head>
<title>m6.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #0033b3;}
.s1 { color: #080808;}
.s2 { color: #8c8c8c; font-style: italic;}
.s3 { color: #067d17;}
.s4 { color: #1750eb;}
</style>
</head>
<body bgcolor="#ffffff">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#c0c0c0" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
m6.py</font>
</center></td></tr></table>
<pre><span class="s0">import </span><span class="s1">cv2</span>
<span class="s0">import </span><span class="s1">time</span>
<span class="s0">import </span><span class="s1">numpy </span><span class="s0">as </span><span class="s1">np</span>

<span class="s0">def </span><span class="s1">perform_blink_tracking():</span>
    <span class="s2"># Load the pre-trained model for face and eye detection</span>
    <span class="s1">face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + </span><span class="s3">'haarcascade_frontalface_default.xml'</span><span class="s1">)</span>
    <span class="s1">eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + </span><span class="s3">'haarcascade_eye.xml'</span><span class="s1">)</span>

    <span class="s2"># Open a video stream (adjust camera index or video file path as needed)</span>
    <span class="s1">cap = cv2.VideoCapture(</span><span class="s4">1</span><span class="s1">)  </span><span class="s2"># 0 for default camera, or provide a path to a video file</span>

    <span class="s0">if not </span><span class="s1">cap.isOpened():</span>
        <span class="s1">print(</span><span class="s3">&quot;Error: Could not open video stream or file.&quot;</span><span class="s1">)</span>
        <span class="s0">return</span>

    <span class="s2"># Get screen resolution</span>
    <span class="s1">screen_width, screen_height = </span><span class="s4">1920</span><span class="s1">, </span><span class="s4">1080  </span><span class="s2"># Adjust as per your screen resolution</span>

    <span class="s2"># Create a full-screen window</span>
    <span class="s1">cv2.namedWindow(</span><span class="s3">'Blink Tracking'</span><span class="s1">, cv2.WND_PROP_FULLSCREEN)</span>
    <span class="s1">cv2.setWindowProperty(</span><span class="s3">'Blink Tracking'</span><span class="s1">, cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)</span>

    <span class="s2"># Start time for tracking duration</span>
    <span class="s1">start_time = time.time()</span>

    <span class="s2"># Initialize variables for zooming on eyes</span>
    <span class="s1">zoom_factor = </span><span class="s4">10.5  </span><span class="s2"># Zoom factor for eyes</span>
    <span class="s1">blink_detected = </span><span class="s0">False</span>
    <span class="s1">blink_counter = </span><span class="s4">0</span>

    <span class="s0">while </span><span class="s1">time.time() - start_time &lt; </span><span class="s4">10</span><span class="s1">:  </span><span class="s2"># Track blinks for 10 seconds</span>
        <span class="s1">ret, frame = cap.read()</span>
        <span class="s0">if not </span><span class="s1">ret:</span>
            <span class="s0">break</span>

        <span class="s2"># Convert frame to grayscale for face and eye detection</span>
        <span class="s1">gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)</span>

        <span class="s2"># Detect faces in the grayscale frame</span>
        <span class="s1">faces = face_cascade.detectMultiScale(gray, </span><span class="s4">1.3</span><span class="s1">, </span><span class="s4">5</span><span class="s1">)</span>

        <span class="s2"># Loop over detected faces</span>
        <span class="s0">for </span><span class="s1">(x, y, w, h) </span><span class="s0">in </span><span class="s1">faces:</span>
            <span class="s2"># Draw a rectangle around the face</span>
            <span class="s1">cv2.rectangle(frame, (x, y), (x + w, y + h), (</span><span class="s4">255</span><span class="s1">, </span><span class="s4">0</span><span class="s1">, </span><span class="s4">0</span><span class="s1">), </span><span class="s4">2</span><span class="s1">)</span>

            <span class="s2"># Extract the region of interest (ROI) for eyes</span>
            <span class="s1">roi_gray = gray[y:y + h, x:x + w]</span>
            <span class="s1">roi_color = frame[y:y + h, x:x + w]</span>

            <span class="s2"># Detect eyes within the face ROI</span>
            <span class="s1">eyes = eye_cascade.detectMultiScale(roi_gray)</span>

            <span class="s2"># Loop over detected eyes</span>
            <span class="s0">for </span><span class="s1">(ex, ey, ew, eh) </span><span class="s0">in </span><span class="s1">eyes:</span>
                <span class="s2"># Draw a rectangle around each eye</span>
                <span class="s1">cv2.rectangle(roi_color, (ex, ey), (ex + ew, ey + eh), (</span><span class="s4">0</span><span class="s1">, </span><span class="s4">255</span><span class="s1">, </span><span class="s4">0</span><span class="s1">), </span><span class="s4">2</span><span class="s1">)</span>

                <span class="s2"># Check for blink (example condition based on eye aspect ratio)</span>
                <span class="s0">if </span><span class="s1">blink_detected:</span>
                    <span class="s2"># Zoom in on the eyes region</span>
                    <span class="s1">roi_startX = max(</span><span class="s4">0</span><span class="s1">, x + ex - int(ew * zoom_factor))</span>
                    <span class="s1">roi_startY = max(</span><span class="s4">0</span><span class="s1">, y + ey - int(eh * zoom_factor))</span>
                    <span class="s1">roi_endX = min(frame.shape[</span><span class="s4">1</span><span class="s1">], x + ex + ew + int(ew * zoom_factor))</span>
                    <span class="s1">roi_endY = min(frame.shape[</span><span class="s4">0</span><span class="s1">], y + ey + eh + int(eh * zoom_factor))</span>

                    <span class="s2"># Zoomed eyes ROI</span>
                    <span class="s1">eyes_roi = frame[roi_startY:roi_endY, roi_startX:roi_endX]</span>
                    <span class="s1">eyes_roi = cv2.resize(eyes_roi, (frame.shape[</span><span class="s4">1</span><span class="s1">], frame.shape[</span><span class="s4">0</span><span class="s1">]))  </span><span class="s2"># Resize back to frame size</span>
                    <span class="s1">frame[roi_startY:roi_endY, roi_startX:roi_endX] = eyes_roi</span>

                    <span class="s2"># Display &quot;Blink Fast&quot; text</span>
                    <span class="s1">cv2.putText(frame, </span><span class="s3">&quot;Blink Fast&quot;</span><span class="s1">, (x + ex, y + ey - </span><span class="s4">10</span><span class="s1">), cv2.FONT_HERSHEY_SIMPLEX, </span><span class="s4">0.5</span><span class="s1">, (</span><span class="s4">0</span><span class="s1">, </span><span class="s4">255</span><span class="s1">, </span><span class="s4">0</span><span class="s1">), </span><span class="s4">2</span><span class="s1">)</span>

                    <span class="s2"># Reset blink detection flag</span>
                    <span class="s1">blink_detected = </span><span class="s0">False</span>

        <span class="s2"># Display the output frame</span>
        <span class="s1">cv2.imshow(</span><span class="s3">&quot;Blink Tracking&quot;</span><span class="s1">, frame)</span>
        <span class="s0">if </span><span class="s1">cv2.waitKey(</span><span class="s4">1</span><span class="s1">) &amp; </span><span class="s4">0xFF </span><span class="s1">== ord(</span><span class="s3">'q'</span><span class="s1">):</span>
            <span class="s0">break</span>

    <span class="s2"># Release the video stream and close all windows</span>
    <span class="s1">cap.release()</span>
    <span class="s1">cv2.destroyAllWindows()</span>

<span class="s0">if </span><span class="s1">__name__ == </span><span class="s3">&quot;__main__&quot;</span><span class="s1">:</span>
    <span class="s1">perform_blink_tracking()</span>
</pre>
</body>
</html>